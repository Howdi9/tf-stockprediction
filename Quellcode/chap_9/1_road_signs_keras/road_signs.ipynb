{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Projekt 1: Verkehrszeichenerkennung mit Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d371e4fcda2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import losses,  metrics, regularizers, utils\n",
    "from tensorflow.keras.layers import InputLayer, Dropout, BatchNormalization, MaxPooling2D, Conv2D,Flatten,Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import genfromtxt\n",
    "from pandas import read_csv\n",
    "from skimage import color, exposure, transform, io\n",
    "from PIL import Image\n",
    "from textwrap import wrap\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unter MacOS muss das Backend von matplotlib  veraendert werden, \n",
    "ansonsten gibt es eine Fehlermeldung\n",
    "matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 32\n",
    "MAX_PICTURES_PER_CLASS = 200\n",
    "NUM_BATCHES = 64\n",
    "NUM_EPOCHS = 40 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMAGES_PATH = './img/train'\n",
    "TEST_IMAGES_PATH = \"./img/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    " # Das erste Bild von jeder Kategorie wird zwischengespeichert\n",
    " # und angezeigt\n",
    "first_images = []\n",
    "num_roadsign_classes = 0  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion, die das Bild zu einer bestimmten Größe skaliert, \n",
    "da jedes Bild innerhalb der Verzeichnisse unterschiedlichen Grössen\n",
    "besitzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    img = np.asarray(img)\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Funktion adaptiert von readTrafficSigns.py vom Institut für Neuroninformatik    \n",
    "def load_roadsigns_data(rootpath):\n",
    "\n",
    "    images = [] # Array von Bilder images\n",
    "    labels = [] # Array von corresponding labels\n",
    "    \n",
    "    nbOfImages =0\n",
    "    global num_roadsign_classes\n",
    "    \n",
    "    #  Hinweis: unter MacOS wird der versteckte Ordner\n",
    "    # \".DS_STORE\" mitgezählt\n",
    "    num_roadsign_classes = len([pic for pic in os.listdir(rootpath) if not pic.startswith(\".\")])\n",
    "\n",
    "    # Die Schleife geht über alle Verzeichnisse\n",
    "    for c in range(0,num_roadsign_classes):\n",
    "        prefix = rootpath + '/' + format(c, '05d') + '/' # Unterverzeichnis für die Kategorie\n",
    "        gt_file = open(prefix + 'GT-'+ format(c, '05d') + '.csv') # annotations file\n",
    "        gt_reader = csv.reader(gt_file, delimiter=';') \n",
    "        next(gt_reader) # Iterator\n",
    "        \n",
    "         # Jede zeile der GT-XXXXX.csv Datei wird eingelesen\n",
    "        for row_index, row in enumerate(gt_reader):\n",
    "            jpgfile = Image.open(prefix + row[0])\n",
    "            nbOfImages +=1\n",
    "\n",
    "            if(row_index>=MAX_PICTURES_PER_CLASS):\n",
    "                break\n",
    "            # Wir wollen nicht durch alle Bilder pro Verzeichnis durchgehen (das Training kann länger dauern)\n",
    "            # wir setzten eine Grenze von 250 zu analysierenden Bildern pro \n",
    "            # Verzeichnis. Erhöhen Sie den Wert von MAX_PICTURE_PER_CLASS,\n",
    "            # wenn Sie alle Bilder berücksichtigen möchten\n",
    "            gs_image = preprocess_image(jpgfile) # Skaliert das Bild\n",
    "            images.append(gs_image) \n",
    "            labels.append(row[7]) # die Spalte 8 beinhaltet das Label\n",
    "\n",
    "            if(row_index==0):\n",
    "                first_images.append(gs_image)\n",
    "            \n",
    "            if(nbOfImages%1000 == 0):\n",
    "                print(\"Analysierte Bilder :{}\".format(nbOfImages))\n",
    "\n",
    "        gt_file.close()\n",
    "\n",
    "    return np.array(images)/255.0, np.array(to_categorical(labels, num_classes=num_roadsign_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Gibt den Namen der Kategorie zurück\n",
    "def get_roadsign_name(index):\n",
    "    return sign_names.values[index][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Ausgabe der Bilder\n",
    "def display_roadsigns_classes():\n",
    "    plt.rc('font', size=6)    \n",
    "    plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "    fig, axarr = plt.subplots(6,8)\n",
    "    num = 0\n",
    "    for i in range(0,6):\n",
    "        for p in range(0,8):\n",
    "            axarr[i][p].axis('off')\n",
    "            if(num<num_roadsign_classes):\n",
    "                axarr[i,p].imshow(first_images[num],interpolation='nearest')\n",
    "                roadsign_name = \"\\n\".join(wrap(get_roadsign_name(num),15))\n",
    "                axarr[i,p].set_title(\"[\" + str(num) + \"]\\n\"+roadsign_name)\n",
    "                num +=1\n",
    "    fig.suptitle('German Traffic Sign Recognition Benchmark',fontsize=16,fontweight=\"bold\")\n",
    "    plt.subplots_adjust(hspace=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Aufbau des Keras Modells \n",
    "def build_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.BatchNormalization( input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape =\n",
    "     (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(tf.keras.layers.Conv2D(64, (5, 5), strides=(2,2), activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv2D(128, (5, 5), strides=(2,2), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(num_roadsign_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Namen der Verkehrsschilder werden geladen\n",
    "sign_names = read_csv('road_signs_names.csv', delimiter=',',dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir laden die Bilder und die Labels dank der load_roadsigns_data() Funktion\n",
    "images, labels = load_roadsigns_data(TRAIN_IMAGES_PATH)\n",
    "images, labels  = shuffle(images,labels,random_state=42)\n",
    "trainImages, valImages, trainLabels, valLabels = train_test_split(images, labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Verkehrsschilder werden angezeigt\n",
    "display_roadsigns_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.001)\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Da wir ein Klassifikationsaufgabe haben, verwenden wir categorical_crossentropy\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics = [\"accuracy\"])#,\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagegenerator für die Trainingsdaten\n",
    "train_imagedatagenerator = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=[0.4,1.1],\n",
    "    shear_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imagedatagenerator.fit(trainImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator für die Validierunsdaten\n",
    "val_imagedatagenerator = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=[0.4,1.1],\n",
    "    shear_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_imagedatagenerator.fit(valImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Training des Modells Ohne Datenaugmentierung\n",
    "model.fit(trainImages,trainLabels, epochs=NUM_EPOCHS, batch_size=NUM_BATCHES,verbose=1,validation_data=(valImages,valLabels),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Training des Modells mit Datenaugmentierung\n",
    "# model.fit_generator(train_imagedatagenerator.flow(trainImages, trainLabels, batch_size=NUM_BATCHES), steps_per_epoch= trainImages.shape[0]/NUM_BATCHES, epochs=NUM_EPOCHS,validation_data=(valImages,valLabels),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir laden nun das Testdataset\n",
    "test_images, test_labels = load_roadsigns_data(TEST_IMAGES_PATH)\n",
    "test_images, test_labels  = shuffle(test_images,test_labels,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_images,test_labels,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = model.evaluate(val_imagedatagenerator.flow(valImages,valLabels),verbose=1)\n",
    "# scores = model.evaluate(valImages,valLabels,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loss:', scores[0])\n",
    "print('Accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das Model wird gespeichert\n",
    "model.save('road_signs_model.h5')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
