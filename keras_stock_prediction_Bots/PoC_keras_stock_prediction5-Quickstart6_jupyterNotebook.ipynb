{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f4a9f59",
   "metadata": {},
   "source": [
    "Source: https://github.com/Howdi9/tf-stockprediction/blob/master/keras_stock_prediction_Bots/PoC_keras_stock_prediction5-Quickstart6_jupyterNotebook.ipynb\n",
    "\n",
    "\n",
    "#### PoC\n",
    "notwendige Dateien sollten im Verzeichnis liegen\n",
    "- GBPUSD_M5_ab2019.01.21.csv     - OHLC-Candlestick Währungs-Wechselkurs Daten von USD gegen GBP\n",
    "- GBPUSD_M5_ab2019.01.21.csv.gz  - gespeicherte Normalisierungswerte der CSV\n",
    "- GBPUSD_M5_ab2019.01.21.csv.h5  - gespeichertes Neuronales-Netz (Tensorflow), um es nicht mit jedem Durchgang neu berechnen zu müssen\n",
    "- GBPUSD_M5_ab2019.01.21.csv.png - gespeicherte Plot-Ausgabe des Backtradings zu Demozwecken, Anzeige nur im Markdown\n",
    "- PoC_ keras_stock_prediction5-Quickstart6.py\n",
    "\n",
    "#### Config: \n",
    "- notwendige Lib (siehe unten)\n",
    "  - Tensorflow \n",
    "  - Backtrader \n",
    "\n",
    "\n",
    "#### Ablauf\n",
    "- Schritt 0: venv: virtuellen Environment einrichten:\n",
    "- Schritt 1: Config und Einrichtung\n",
    "- Schritt 2: CSV (historischen 5min-Wechselkurse GBP-USD) trainiert ein Neuronales Netz via Keras-Tensorflow\n",
    "- Schritt 3: NN wird mit identischer CSV verwendet um eine Tradingstrategie mit den zu testen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027526c5",
   "metadata": {},
   "source": [
    "#### Korrekte python-version aktivieren\n",
    "\n",
    "\n",
    "Getestete Python versionen\n",
    "\n",
    "  - Nur Python 3.7: Zuerst verwendete Version (via conda installiert)\n",
    "  - TensorFlow 2.1.0 ist nur bis 3.7 freigegeben, und wird ab 3.8 nicht mehr angeboten\n",
    "\n",
    "Bei mehreren python-versionen empfielt sich **pyenv** zu verwenden\n",
    "Installierbare python3.7 version, immer die neueste verwenden\n",
    "  - pyenv install --list | grep \" 3\\.7\"\n",
    "\n",
    "Neustes Patchlevel installieren\n",
    "  - pyenv install 3.7.17\n",
    "\n",
    "Version für lokale Kommandline setzen\n",
    "  - pyenv local 3.7.17\n",
    "\n",
    "Python Version überprüfen\n",
    "  - python --version\n",
    "\n",
    "\n",
    "#### Schritt 0: Repository local clonen\n",
    "cd /locales/directory\n",
    "git clone https://github.com/Howdi9/tf-stockprediction\n",
    "\n",
    "#### Schritt 0: venv einrichten\n",
    ".venv erstellen\n",
    "> cd /home/name/local/dir/tf-stockprediction\n",
    "\n",
    "> python3 -m venv .venv\n",
    "\n",
    "> source /home/name/Schreibtisch/TradingBot/Git_Clone/tf-stockprediction/.venv/bin/activate\n",
    "\n",
    "Python Version überprüfen\n",
    "> python --version\n",
    "\n",
    "\n",
    "PIP updaten und LIBs installieran\n",
    "> pip install --upgrade pip\n",
    "\n",
    "#### Schritt 0: Requirements installieren\n",
    "pip install -r requirements.txt\n",
    "\n",
    "\n",
    "Händische installation:\n",
    "\n",
    "<div style=\"background-color: #f0f0f0; padding: 10px; border-radius: 5px;\">\n",
    "Achtung: \"pip install tensorflow\" bring Fehler!!!\n",
    "\tsame for anaconda, but reinstall with tensorflow=2.1 does not solve issue.\n",
    "\t\"conda install tensorflow\" brings tensorflow-estimator 2.2\n",
    "\t\n",
    "\tLösung: Erst install Estimator=2.1 then the rest:\n",
    "\t- conda remove tensorflow\n",
    "\t- conda install tensorflow-estimator=2.1\n",
    "\t- conda install tensorflow-gpu=2.1\n",
    "\thttps://github.com/tensorflow/tensorflow/issues/37525\n",
    "</div>\n",
    "\n",
    "> pip install tensorflow==2.1.0\n",
    "\n",
    "> ~~pip install tensorflow-estimator==2.1.0 (already satisfied)~~\n",
    "\n",
    "> pip install matplotlib==3.2.2\n",
    "\n",
    "> pip install scikit-learn\n",
    "\n",
    "> ~~pip install numpy (already satisfied)~~\n",
    "\n",
    "> pip install joblib\n",
    "\n",
    "\n",
    "\n",
    "#### Backtrader in venv installieren\n",
    "\n",
    "Installation vom Howdi9-Repository (forked)\n",
    "> pip install git+https://github.com/Howdi9/backtrader.git\n",
    "\n",
    "> pip install git+https://github.com/Howdi9/IbPy\n",
    "\n",
    "Alternativ: \n",
    "- zip's downloaden \n",
    "  - https://github.com/Howdi9/backtrader/archive/refs/heads/master.zip\n",
    "  - https://github.com/Howdi9/IbPy/archive/refs/heads/master.zip\n",
    "- local entpacken ->  setup-Datei ausführen\n",
    "> cd C:\\EigeneDateien\\backtrader-master\n",
    "\n",
    "> python setup.py install\n",
    "\n",
    "\n",
    "#### Schließlich jupyter-notebook starten\n",
    "> pip install notebook \n",
    "\n",
    "jupyter-notebook starten\n",
    "> jupyter notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e65ae82",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cf1a92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ubuntu 20.04.6 LTS \\n \\l\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "#Welches OS habe ich? -> lief erfolgreich mit Ubuntu\n",
    "!cat /etc/issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9814e996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/name/Schreibtisch/TradingBot/Git_Clone/tf-stockprediction2/tf-stockprediction/keras_stock_prediction_Bots\r\n"
     ]
    }
   ],
   "source": [
    "#In welchem Verzeichnis bin ich? -> idealerweise ein eigenes Verzeichnis einrichten, dort dbc-file entpacken und dort arbeiten\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a8728dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid=1000(name) gid=1000(name) Gruppen=1000(name),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),79(sapsys),108(kvm),120(lpadmin),133(lxd),134(sambashare),135(docker),137(libvirt),998(ollama)\r\n"
     ]
    }
   ],
   "source": [
    "#Wer bin ich? ->root!\n",
    "!id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91487b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.17\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5ecf2e",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC # Schritt 1: keras_stock_prediction-5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a09808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folgende Parameter in diesem PoC bitte nicht ändern\n",
    "# Anzahl der Datensetze (hier 5min Kerzen), die für Prediction verwendet werden sollen\n",
    "DAYS_BEFORE = 100     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7d175f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl der Tage, die geforcasted werden sollen, \n",
    "DAYS_PREDICT = 2  \n",
    "epochs=100\n",
    "WorkWithSavedNN=True  # True: NN laden von \"./GBPUSD_M5_ab2019.01.21.csv.h5\"\n",
    "                      # False: neues NN trainieren, dauerte 4.7h (mit Standard_DS3_V2, Runtimeversion 15.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0057c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"./\"\n",
    "CSV_FILE  = \"GBPUSD_M5_ab2019.01.21.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bc15d2",
   "metadata": {},
   "source": [
    "Folgende Fehlermeldung kann ignoriert werden, soweit mit fertigem Modell gearbeitet wirde und nicht via GPU-Unterstütung ein neues generiert werden soll.\n",
    "    \n",
    "    2025-10-26 15:48:19.446234: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
    "    2025-10-26 15:48:19.446393: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
    "    2025-10-26 15:48:19.446411: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8871ae3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######Import ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-26 18:55:28.308952: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2025-10-26 18:55:28.309089: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2025-10-26 18:55:28.309106: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "print(\"#######Import ...\")\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "from tensorflow.keras.models import load_model, Sequential                 \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4f46e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fb9492f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######Import activities finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#plt.matplotlib.use('TkAgg') (heute nicht mehr nötig? ist im originalCode nicht auskommentiert!!)\n",
    "import joblib\n",
    "print(\"#######Import activities finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29a5e0e",
   "metadata": {},
   "source": [
    "ausgeführt auf Databricks kommt \"GPU will not be used.\", soweit ausgeführt auf Cluster ohne GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d58f33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "#######CSV einlesen\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------\")\n",
    "print(\"#######CSV einlesen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d402586a",
   "metadata": {},
   "source": [
    "Spalten GBPUSD\n",
    "   (0)Symbole,(1)TimeFrame,(2)Time,(3)Open,(4)High,(5)Low,(6)Close,(7)Volume\n",
    "   EURUSD,D1,2020.05.22 00:00:00,1.22207,1.22333,1.21611,1.21825,52575.0\n",
    "   EURCHF_M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6da12d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File:  ./GBPUSD_M5_ab2019.01.21.csv\n",
      "[1.28574 1.2861  1.28619 ... 1.30952 1.30938 1.30936]\n"
     ]
    }
   ],
   "source": [
    "print(\"File: \", CSV_PATH+CSV_FILE)\n",
    "initial_stock_data = np.loadtxt(\n",
    "    CSV_PATH+CSV_FILE,delimiter=\";\",\n",
    "    skiprows=1,\n",
    "    #max_rows=1000,\n",
    "    usecols=(6),\n",
    "    comments=\"#\",\n",
    "    dtype=float,\n",
    "    #encoding=\"UTF-16\"\n",
    "    )\n",
    "print(initial_stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cc7ee03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######CSV einlesen finished\n"
     ]
    }
   ],
   "source": [
    "print(\"#######CSV einlesen finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8952f171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "#######CSV reshape(-1,1)\n",
      "#######CSV reshape finished\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------------------\")\n",
    "print(\"#######CSV reshape(-1,1)\")\n",
    "initial_stock_data = np.array(initial_stock_data,dtype=\"float\").reshape(-1,1)\n",
    "print(\"#######CSV reshape finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc56a305",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TensorBoard-callbacks\n",
    "stockpred_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\".\\\\CallbackLogs\"\n",
    "#   histogram_freq=1\n",
    "#   write_graph=True\n",
    "#   write_images=True\n",
    "#   update_freq=batch\n",
    "#   profile_batch=\n",
    "#   embeddings_freq=\n",
    "#   embeddings_metadata=\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "095cd2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "####### MinMaxScaler fit_transform \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./GBPUSD_M5_ab2019.01.21.csv.gz']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalisierung der Werte\n",
    "print(\"---------------------------------\")\n",
    "print(\"####### MinMaxScaler fit_transform \")\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "stock_data = min_max_scaler.fit_transform(initial_stock_data)\n",
    "joblib.dump(min_max_scaler, './' + CSV_FILE + '.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "054d25e0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### Speicherung der normalisierten np-Werte als Dump: ./GBPUSD_M5_ab2019.01.21.csv.gz\n",
      "####### MinMaxScaler fit_transform finished\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"####### Speicherung der normalisierten np-Werte als Dump: ./\" + CSV_FILE + \".gz\")\n",
    "print(\"####### MinMaxScaler fit_transform finished\")\n",
    "print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffaf9e6d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Reorganisiert die Daten\n",
    "def arrange_data(data, daysH, daysF):\n",
    "    days_before_values = [] # T- days\n",
    "    days_values = []  # T\n",
    "    for i in range(len(data) - (daysH+daysF-1)):\n",
    "       days_before_values.append(data[i:(i+daysH)])\n",
    "       days_values.append(data[(i+daysH):(i+daysH+daysF)])\n",
    "    return np.array(days_before_values),np.array(days_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0592bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_before_values, days_values =  arrange_data(stock_data,DAYS_BEFORE, DAYS_PREDICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4da21801",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Wir nehmen nur ein Teil des Datasets, um das Training durchzuführen\n",
    "# Der Rest (X_test und Y_test) wird für die \"virtuelle\" Prognose benutzt \n",
    "# Splitting des Datasets\n",
    "def split_to_percentage(data,percentage):                                                           # 1D\n",
    "    return  data[0: int(len(data)*percentage)] , data[int(len(data)*percentage):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c2c5674",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "X_train, X_test = split_to_percentage(days_before_values,0.8) #  80:20 Eingabedaten\n",
    "Y_train, Y_test = split_to_percentage(days_values,0.8) # 80:20 Ausgabedaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b6a448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.metrics import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be78451b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######Model load\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_215585/1126475541.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Das Modell wird geladen, passiert ohne Output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#######Model load\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mstock_model\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mCSV_FILE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#######Model load finished\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Schreibtisch/TradingBot/Git_Clone/tf-stockprediction2/tf-stockprediction/.venv/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    144\u001b[0m   if (h5py is not None and (\n\u001b[1;32m    145\u001b[0m       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Schreibtisch/TradingBot/Git_Clone/tf-stockprediction2/tf-stockprediction/.venv/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     model = model_config_lib.model_from_config(model_config,\n\u001b[1;32m    168\u001b[0m                                                custom_objects=custom_objects)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "if not WorkWithSavedNN: \n",
    "    # Definition des Keras Modells\n",
    "\n",
    "    stock_model = Sequential()\n",
    "\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"#########add first LSTM\")\n",
    "    stock_model.add(LSTM(50,input_shape=(DAYS_BEFORE,1), return_sequences=True))     # stateful=True\n",
    "    print(\"#########add LSTM finished\")\n",
    "\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"#########add second LSTM\")\n",
    "    stock_model.add(LSTM(20,activation=\"tanh\"))\n",
    "    #stock_model.add(LSTM(5,activation=\"relu\"))\n",
    "    print(\"#########add LSTM finished\")\n",
    "\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"#########add Dense\")\n",
    "    stock_model.add(Dense(DAYS_PREDICT))\n",
    "    print(\"#########add Dense finished\")\n",
    "\n",
    "    sgd = SGD(learning_rate=0.01)\n",
    "\n",
    "    #Model compiling passiert ohne Output\n",
    "    stock_model.compile(loss=\"mean_squared_error\", optimizer=sgd, metrics=[MeanSquaredError()])\n",
    "\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"#######Model fit\")\n",
    "    print(\"\")\n",
    "    batch_size=None\n",
    "    stock_model.fit(X_train, Y_train, batch_size, epochs, verbose=2, callbacks=[stockpred_callback])\n",
    "    print(\"\")\n",
    "    print(\"#######Model fit finished\")\n",
    "    print(\"---------------------------------\")\n",
    "    stock_model.summary()\n",
    "    print(\"\")\n",
    "\n",
    "    # Das Modell wird gespeichert, passiert ohne Output\n",
    "    print(\"#######Model save\")\n",
    "    stock_model.save('./' + CSV_FILE + \".h5\")\n",
    "    print(\"#######Model save finished\")\n",
    "else:\n",
    "    # Das Modell wird geladen, passiert ohne Output\n",
    "    print(\"#######Model load\")\n",
    "    stock_model= tf.keras.models.load_model('./' + CSV_FILE + \".h5\")\n",
    "    print(\"#######Model load finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91fb88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation der Testdaten\n",
    "print(\"---------------------------------\")\n",
    "print(\"#######Model evaluate\")\n",
    "print(\"\")\n",
    "score, _ = stock_model.evaluate(X_test,Y_test, verbose=2, callbacks=[stockpred_callback])\n",
    "print(\"\")\n",
    "print(\"#######Model evaluate finished\")\n",
    "print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfcc754",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "rmse = math.sqrt(score)\n",
    "print(\"RMSE (RootMeanSquaredError): {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7d446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersage mit den \"unbekannten\" Test-Dataset\n",
    "predictions_on_test = stock_model.predict(X_test, verbose=2, callbacks=[stockpred_callback])\n",
    "print(\"---------------------------------\")\n",
    "print('predictions_on_test: ', predictions_on_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766d64d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_on_test = min_max_scaler.inverse_transform(predictions_on_test)\n",
    "print(\"---------------------------------\")\n",
    "print('predictions_on_test: ', predictions_on_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5115ae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... und mit dem Trainings-Dataset\n",
    "predictions_on_training = stock_model.predict(X_train, verbose=2, callbacks=[stockpred_callback])\n",
    "print(\"---------------------------------\")\n",
    "print('predictions_on_training: ', predictions_on_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d06b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_on_training = min_max_scaler.inverse_transform(predictions_on_training)\n",
    "print(\"---------------------------------\")\n",
    "print('predictions_on_training: ', predictions_on_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84079176",
   "metadata": {},
   "outputs": [],
   "source": [
    "Row_DAYS_PREDICT_Train_1=np.array(predictions_on_training[:,0])\n",
    "Row_DAYS_PREDICT_Test_1=np.array(predictions_on_test[:,0])\n",
    "Row_DAYS_PREDICT_Train_2=np.array(predictions_on_training[:,1])\n",
    "Row_DAYS_PREDICT_Test_2=np.array(predictions_on_test[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b73e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir shiften nach rechts, damit das Testergebnis grafisch direkt nach der Trainingskurve startet.\n",
    "shift_1 = range(len(Row_DAYS_PREDICT_Train_1)-DAYS_PREDICT, len(stock_data) - 1 - (DAYS_BEFORE+DAYS_PREDICT) - 1)\n",
    "shift_2 = range(len(Row_DAYS_PREDICT_Train_2)-DAYS_PREDICT, len(stock_data) - 1 - (DAYS_BEFORE+DAYS_PREDICT) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b50a98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzeige der Kurven mit matplotlib\n",
    "print(\"---------------------------------\")\n",
    "print(\"pyplot Ausgabe: Fenster schließen zum Beenden des Python-Programms\")\n",
    "plt.plot(initial_stock_data, color=\"grey\",label=\"Kurs\", linewidth=2)\n",
    "plt.plot(Row_DAYS_PREDICT_Train_1, label=\"Train Pred1\", color=\"green\", linewidth=1)\n",
    "plt.plot(Row_DAYS_PREDICT_Train_2, label=\"Train Pred2\", color=\"lightgreen\", linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e13a596",
   "metadata": {},
   "source": [
    "plt.plot(shift_3, Row_DAYS_PREDICT_Test_1, label=\"Test Pred1\", color=\"green\", dashes=[6, 2])\n",
    "plt.plot(shift_2, Row_DAYS_PREDICT_Test_2, label=\"Test Pred2\", color=\"lightgreen\", dashes=[6, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfed4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.legend(loc='upper left')\n",
    "#plt.set_xlabel('Zeitachse')\n",
    "#plt.set_ylabel('Kurs in USD')\n",
    "#plt.set_title(\"Kursverlauf\")\n",
    "plt.show()\n",
    "plt.savefig('.' + CSV_FILE + \".png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea74848",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "(Grafik nur bedingt hilfreich)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb7c629",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC # Schritt 2: QuickstartSample6_Indicator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd4bc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_IB = False \n",
    "# True: Live-Verbindung zu InteractiveBroker für Backtesting (Laden Historischer Daten via Broker) oder LiveTrading\n",
    "# False: Verwendung der CSV-Datei zum Datenladen (Nur Backtesting möglich)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7303c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Go_live = False\n",
    "#True: Wenn use_IB=true kann hiermit Live-Trading gestartet werden\n",
    "#False: Kein LiveTrading, nur Laden historischer Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31607d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV-Datei mit historischen Daten laden\n",
    "CSV_PATH = \"./\"\n",
    "CSV_FILE  = \"GBPUSD_M5_ab2019.01.21.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a4c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import (absolute_import, division, print_function,\n",
    "                        unicode_literals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c44cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the backtrader platform\n",
    "import backtrader as bt\n",
    "import datetime  # For datetime objects\n",
    "import os.path  # To manage paths\n",
    "import sys  # To find out the script name (in argv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b935abaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#######Import ...\")\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import matplotlib\n",
    "#import matplotlib.pyplot as plt\n",
    "#import os\n",
    "import math\n",
    "from tensorflow.keras.models import load_model\n",
    "#from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, LSTM\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "#from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff066c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "#matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938b6f8d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "print(\"#######Import activities finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163e5089",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class TensorflowPrediction(bt.Indicator):\n",
    "    lines = ('tfpred',)\n",
    "    params = (('period', 20),)\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.addminperiod(self.params.period)\n",
    "        plotinfo = dict(subplot=False, plotforce=True)\n",
    "        \n",
    "    \n",
    "    def next(self):\n",
    "        lastdataclose1 = math.fsum(self.data.get(size=self.params.period))\n",
    "        self.lines.tfpred[0] = lastdataclose1 / self.p.period                     #<<- funktioniert!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503df52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Stratey\n",
    "class TestStrategy(bt.Strategy):\n",
    "    params = (('maperiod', 15), ('TFperiod', 20),)\n",
    "\n",
    "    def __init__(self):\n",
    "        # Keep a reference to the \"close\" line in the data[0] dataseries\n",
    "        self.dataclose = self.datas[0].close\n",
    "                \n",
    "        # To keep track of pending orders and buy price/commission\n",
    "        self.order = None\n",
    "        self.buyprice = None\n",
    "        self.buycomm = None\n",
    "        \n",
    "        # Add a MovingAverageSimple indicator\n",
    "        self.sma = bt.indicators.SimpleMovingAverage(self.datas[0], period=self.params.maperiod)\n",
    "        self.TF = TensorflowPrediction()\n",
    "\n",
    "    def next(self):\n",
    "        # Simply log the closing price of the series from the reference\n",
    "        self.log('Close, %.2f' % self.dataclose[0])       \n",
    "        \n",
    "        # Check if an order is pending ... if yes, we cannot send a 2nd one\n",
    "        if self.order:\n",
    "            return\n",
    "\n",
    "        # Check if we are in the market\n",
    "        if not self.position:\n",
    "\n",
    "            # Not yet ... we MIGHT BUY if ...\n",
    "            if self.dataclose[0] > self.sma[0]:\n",
    "    \n",
    "                # BUY, BUY, BUY!!! (with all possible default parameters)\n",
    "                self.log('BUY CREATE, %.2f' % self.dataclose[0])\n",
    "\n",
    "                # Keep track of the created order to avoid a 2nd order\n",
    "                self.order = self.buy()\n",
    "\n",
    "        else:\n",
    "\n",
    "            if self.dataclose[0] < self.sma[0]:\n",
    "                # SELL, SELL, SELL!!! (with all possible default parameters)\n",
    "                self.log('SELL CREATE, %.2f' % self.dataclose[0])\n",
    "\n",
    "                # Keep track of the created order to avoid a 2nd order\n",
    "                self.order = self.sell()\n",
    "\n",
    "\n",
    "    def log(self, txt, dt=None):\n",
    "        ''' Logging function fot this strategy'''\n",
    "        dt = dt or self.datas[0].datetime.date(0)\n",
    "        print('%s, %s' % (dt.isoformat(), txt))\n",
    "        \n",
    "    def notify_order(self, order):\n",
    "        if order.status in [order.Submitted, order.Accepted]:\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            return\n",
    "\n",
    "        # Check if an order has been completed\n",
    "        # Attention: broker could reject order if not enough cash\n",
    "        if order.status in [order.Completed]:\n",
    "            if order.isbuy():\n",
    "                self.log(\n",
    "                    'BUY EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %\n",
    "                    (order.executed.price,\n",
    "                     order.executed.value,\n",
    "                     order.executed.comm))\n",
    "\n",
    "                self.buyprice = order.executed.price\n",
    "                self.buycomm = order.executed.comm\n",
    "            else:  # Sell\n",
    "                self.log('SELL EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %\n",
    "                         (order.executed.price,\n",
    "                          order.executed.value,\n",
    "                          order.executed.comm))\n",
    "\n",
    "            self.bar_executed = len(self)\n",
    "\n",
    "        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n",
    "            self.log('Order Canceled/Margin/Rejected')\n",
    "\n",
    "        # Write down: no pending order\n",
    "        self.order = None\n",
    "\n",
    "    def notify_trade(self, trade):\n",
    "        if not trade.isclosed:\n",
    "            return\n",
    "\n",
    "        self.log('OPERATION PROFIT, GROSS %.2f, NET %.2f' %\n",
    "                 (trade.pnl, trade.pnlcomm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c442c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backtrader.feeds import GenericCSVData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff7be1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    if use_IB:\n",
    "        if Go_live:\n",
    "            print(\" \")\n",
    "            print('Beginn Go_live')\n",
    "            dataLoad = bt.feeds.IBData(\n",
    "                dataname='GBP.USD-CASH-IDEALPRO', \n",
    "                host='127.0.0.1', \n",
    "                port=7496, \n",
    "                timeframe=bt.TimeFrame.TFrame(\"Minutes\"),\n",
    "                rtbar=False,\n",
    "                compression = 5\n",
    "                )\n",
    "            print('Ende Go_live')\n",
    "        else:         \n",
    "            print(' ')\n",
    "            print('Beginn DataLoad historical')\n",
    "            dataLoad = bt.feeds.IBData(\n",
    "                dataname='GBP.USD-CASH-IDEALPRO', \n",
    "                host='127.0.0.1', \n",
    "                port=7496, \n",
    "                historical=True,\n",
    "                timeframe=bt.TimeFrame.TFrame(\"Minutes\"),\n",
    "                compression = 5\n",
    "                )\n",
    "            print('Ende DataLoad historical')\n",
    "    else: \n",
    "        print(\" \")\n",
    "        print('Beginn Datenladen CSV')\n",
    "         \n",
    "        # Create a Data Feed\n",
    "        FILEPATH = CSV_PATH + CSV_FILE\n",
    "        print (\"FILEPATH: \", FILEPATH)\n",
    "        dataLoad = GenericCSVData(\n",
    "            dataname = CSV_PATH + CSV_FILE,\n",
    "            separator = \";\",\n",
    "            dtformat = ('%d.%m.%Y %H:%M'),\n",
    "            datetime = 2,\n",
    "            time = -1,\n",
    "            open = 3,\n",
    "            high = 4,\n",
    "            low = 5,\n",
    "            close = 6,\n",
    "            volume = 7,\n",
    "            openinterest = -1,\n",
    "            nullvalue = 0.0,\n",
    "            header = True\n",
    "        )\n",
    "        print('Ende Datenladen CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d20437",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" \")\n",
    "print('Beginn: Laden des Models')\n",
    "stock_model= tf.keras.models.load_model(\"./GBPUSD_M5_ab2019.01.21.csv.h5\")\n",
    "print('Ende')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8de975",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\" \")\n",
    "print('Beginn: Laden min_max_scaler')\n",
    "min_max_scaler = joblib.load('./GBPUSD_M5_ab2019.01.21.csv.gz')\n",
    "print(\"Ende\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5228e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cerebro entity\n",
    "print(\" \")\n",
    "print('Beginn: bt.Cerebro()')\n",
    "cerebro = bt.Cerebro()\n",
    "print('Ende: bt.Cerebro()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f879872",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Add a strategy\n",
    "print(\" \")\n",
    "print('Beginn: cerebro.addstrategy(TestStrategy)')\n",
    "cerebro.addstrategy(TestStrategy)\n",
    "print('Ende')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226feec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Data Feed to Cerebro\n",
    "print(\" \")\n",
    "print('Beginn: cerebro.adddata(data)')\n",
    "cerebro.adddata(dataLoad)\n",
    "print('Ende')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d045f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our desired cash start\n",
    "cerebro.broker.setcash(10000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c770a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a FixedSize sizer according to the stake\n",
    "cerebro.addsizer(bt.sizers.FixedSize, stake=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d8b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the commission\n",
    "cerebro.broker.setcommission(commission=0.0)\n",
    "#cerebro.setbroker(bt.brokers.IBBroker(**storekwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b191f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the starting conditions\n",
    "print(\" \")\n",
    "print('Starting Portfolio Value: %.2f' % cerebro.broker.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c3f45",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Run over everything\n",
    "print(\" \")\n",
    "print(\"Beginn: cerebro.run()\")\n",
    "cerebro.run()\n",
    "print(\"Ende run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc879f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the final result\n",
    "print(\" \")\n",
    "print('Final Portfolio Value: %.2f' % cerebro.broker.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98626bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the result\n",
    "cerebro.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabd14e3",
   "metadata": {},
   "source": [
    "Plotting funktioniert mit Databricks leider nicht!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c5dfa3",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912de54a",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC Beispiel-Plot\n",
    "MAGIC\n",
    "MAGIC ![Beispiel-Plot](./QuickstartSample5.png)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
